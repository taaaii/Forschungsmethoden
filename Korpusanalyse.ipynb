{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fe2c23e7aed9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "from Scripte.korpus import Korpus\n",
    "from Scripte.settings import Settings\n",
    "\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from spacy.lang.de import German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\") # oder md  oder lg  wenn heruntergeladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _convert_text(text:str) -> str:\n",
    "    replacements = [(r\"http.+?\\s\", \" \"), (r\"([a-z])([A-Z])\", r\"\\1 \\2\"), (r\"\u0001\", \"\"), \n",
    "                    (r\"\u0002\", \"\"), (r\"\\*{2,}\", \"\"), (\"_+\", \"\"), ]\n",
    "    for old, new in reversed(replacements):\n",
    "        text = text.replace(old, new)\n",
    "    return _convert_entities(text)\n",
    "\n",
    "def _convert_entities(text:str) -> str:\n",
    "    doc = nlp(text)\n",
    "    for entity in reversed(doc.ents):\n",
    "        text = text[:entity.start_char] + entity.label_ + text[entity.end_char:]\n",
    "    return text\n",
    "    \n",
    "\n",
    "def _convert_wordcount(number: str) -> int:\n",
    "    return int(number.replace(\".\", \"\"))\n",
    "\n",
    "def _convert_release(date:str):\n",
    "    return datetime.strptime(date.strip(), \"%d.%m.%Y\")\n",
    " \n",
    "def old_create_df(path, gender):\n",
    "    data = reduce(lambda a, b: a.append(b, ignore_index= True), tqdm([create_part(x) for x in path]))\n",
    "    data[\"gender\"] = gender\n",
    "    return data\n",
    "\n",
    "def create_df(path, gender, genre):\n",
    "    data = pd.concat([create_part(x) for x in tqdm(path)], ignore_index=True)\n",
    "    data[\"gender\"] = gender\n",
    "    data[\"genre\"] = genre\n",
    "    return data\n",
    "\n",
    "def contains_words(string : str, words) -> bool:\n",
    "    return any(x in string for x in words)\n",
    "\n",
    "def create_part(file) -> pd.DataFrame:\n",
    "    start = json.load(open(file))\n",
    "    x = pd.DataFrame.from_dict(start[\"chapters\"], orient= \"index\", columns=[\"text\", \"wordcount\"])\n",
    "    x[\"text\"] = x[\"text\"].apply(_convert_text)\n",
    "    x[\"wordcount\"] = x[\"wordcount\"].apply(_convert_wordcount)\n",
    "    x[\"novel\"] = re.sub(r\"\\W\", \" \", start[\"title\"])\n",
    "    x[\"release\"] = _convert_release(start[\"release\"])\n",
    "    return x \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Korpus aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "krimi_W = [x for x in Path(\"./jsondata/krimis/W\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "krimi_M = [x for x in Path(\"./jsondata/krimis/M\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "#horror\n",
    "hor_W= [x for x in Path(\"./jsondata/horror/W\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "hor_M= [x for x in Path(\"./jsondata/horror/M\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "hor_unsp= [x for x in Path(\"./jsondata/horror/unspecified\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "#abenteuer \n",
    "aben_W= [x for x in Path(\"./jsondata/abenteuer/W\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "aben_M= [x for x in Path(\"./jsondata/abenteuer/M\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "aben_unsp= [x for x in Path(\"./jsondata/abenteuer/unspecified\").glob('**/*') if x.is_file() if x.suffix == \".json\"]\n",
    "\n",
    "#combined\n",
    "json_M = krimi_M + hor_M + aben_M\n",
    "json_W = krimi_W + hor_W + aben_W\n",
    "json_unsp = hor_unsp + aben_unsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Diese Schritte brauchen eine Weile. Wenn ihr sie einmal durch habt, könnt ihr unten CSV save/ load verwenden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_krimi_M = create_df(krimi_M,\"M\", \"krimi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_krimi_W = create_df(krimi_W,\"W\",\"krimi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_hor_M = create_df(hor_M, \"M\", \"horror\")\n",
    "data_hor_W = create_df(hor_W,\"W\",\"horror\")\n",
    "data_hor_unsp = create_df(hor_unsp,\"unsp\", \"horror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_aben_M = create_df(aben_M, \"M\", \"abenteuer\")\n",
    "data_aben_W = create_df(aben_W,\"W\",\"abenteuer\")\n",
    "data_aben_unsp = create_df(aben_unsp,\"unsp\", \"abenteuer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#data_krimi_full = pd.concat([data_krimi_M, data_krimi_W],ignore_index=True)\n",
    "#data_aben_full = pd.concat([data_aben_M, data_aben_W, data_aben_unsp],ignore_index=True)\n",
    "data_hor_full = pd.concat([data_hor_M, data_hor_W, data_hor_unsp],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Summen der Wörter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load and save from csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#data_krimi_full.to_csv(\"csv_data_krimi_full.csv\", sep =\"|\")\n",
    "#data_aben_full.to_csv(\"csv_data_aben_full.csv\", sep=\"|\")\n",
    "#data_hor_full.to_csv(\"csv_data_hor_full.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_krimi_full= pd.read_csv(\"csv_data_krimi_full.csv\", sep =\"|\")\n",
    "data_aben_full= pd.read_csv(\"csv_data_aben_full.csv\", sep=\"|\")\n",
    "data_hor_full = pd.read_csv(\"csv_data_hor_full.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## build from csv files all permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_krimi_M = data_krimi_full.loc[data_krimi_full[\"gender\"] == \"M\"]\n",
    "data_krimi_W = data_krimi_full.loc[data_krimi_full[\"gender\"] == \"W\"]\n",
    "data_aben_M = data_aben_full.loc[data_aben_full[\"gender\"] == \"M\"]\n",
    "data_aben_W = data_aben_full.loc[data_aben_full[\"gender\"] == \"W\"]\n",
    "data_aben_unsp = data_aben_full.loc[data_aben_full[\"gender\"] == \"unsp\"]\n",
    "data_hor_M = data_hor_full.loc[data_hor_full[\"gender\"] == \"M\"]\n",
    "data_hor_W = data_hor_full.loc[data_hor_full[\"gender\"] == \"W\"]\n",
    "data_hor_unsp = data_hor_full.loc[data_hor_full[\"gender\"] == \"unsp\"]\n",
    "\n",
    "# full gender views\n",
    "\n",
    "data_all_M = pd.concat([data_krimi_M, data_aben_M, data_hor_M], ignore_index=True)\n",
    "data_all_W = pd.concat([data_krimi_W, data_hor_W, data_aben_W], ignore_index=True)\n",
    "data_all_unsp = pd.concat([data_aben_unsp, data_hor_unsp], ignore_index=True)\n",
    "\n",
    "data_all = pd.concat([data_krimi_full, data_aben_full, data_hor_full], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analyse und Berechnung\n",
    "\n",
    "## Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joined_text_krimi_M = data_krimi_M.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_krimi_W = data_krimi_W.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_krimi_full = pd.concat([joined_text_krimi_M,joined_text_krimi_W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joined_text_aben_W = data_aben_W.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_aben_M = data_aben_M.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_aben_unsp = data_aben_unsp.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_aben_full = pd.concat([joined_text_aben_M, joined_text_aben_W, joined_text_aben_unsp])\n",
    "\n",
    "joined_text_hor_W = data_hor_W.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_hor_M = data_hor_M.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_hor_unsp = data_hor_unsp.groupby('novel')['text'].apply(' '.join)\n",
    "joined_text_hor_full = data_hor_full.groupby('novel')[\"text\"].apply(' '.join)\n",
    "\n",
    "joined_text_M_full = pd.concat([joined_text_krimi_M,  joined_text_aben_M]) #joined_text_hor_M,\n",
    "joined_text_W_full = pd.concat([joined_text_krimi_W,  joined_text_aben_W])#joined_text_hor_W,\n",
    "joined_text_unsp_full = pd.concat([joined_text_aben_unsp, joined_text_hor_unsp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joined_text_all = data_all.groupby('novel')['text'].apply(' '.join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dieser Schritt braucht etwas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "brut_list = 'brutal schlagen schlug mord misshandeln vergewaltigen überfall tod töten tot treten tritt trat verfolgen hart extrem attacke angriff angreifen metzeln reißen missbrauch zerstören prügel rücksichtslos qual quälen blut griff gewalt tat härte diktator krieg schlacht anschlag schläge terror folter killer teulisch gemein brechen bombe sadistisch erbarmungslos barbarisch knochen verletzen roh grob kampf waffen messer knüppel stoßen lust sexuell diebstahl vandalismus amok belästigen mobbing brand demütigen erpressen nötigung rassismus sabotage stalker hass psychisch einschüchtern entführung beleidigen schimpfen schrei ohrenbetäubend betäubung drogen spritzen kämpfen boxen knöchel schlitzen brechen gedärme teufel dämon bestie schreck hexe kriminalität kriminell liste böse prositution schänden schand entblößen entstellen pervers mafia bosheit fleischwunde gebeine skelett gerippe meucheln umbringen auslöschen kannibale sterben pistole gewehr klinge cutter verbrecher dieb straftäter assassine vergehen entehren unterwerfen entmenscht genitalien faust attentat säge'\n",
    "\n",
    "brut_final = [token.lemma_ for token in nlp(brut_list)]\n",
    "\n",
    "def get_brut_ratio(series)-> pd.DataFrame:\n",
    "    results = []\n",
    "    for novel, text in series.items():\n",
    "        if len(text)> nlp.max_length:\n",
    "            for x in _get_results(novel,text):\n",
    "                results.append(x)\n",
    "                print(f\"LOG: finished {novel}\")\n",
    "        else:\n",
    "            results.append([novel]+calc_data(text))\n",
    "            print(f\"LOG: finished {novel}\")\n",
    "        #results.append([novel, brut_sum, brut_types, total_words, percentage])   \n",
    "    df = pd.DataFrame(results, columns=['novel', 'brut_sum', 'brut_type', 'Total Words', 'Percentage'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def _get_results(novel:str, text:str):\n",
    "    results = []\n",
    "    chunks = [text[i:i+nlp.max_length] for i in range(0, len(text), nlp.max_length)]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        str_ = f\"{novel}_{i}\"\n",
    "        results.append([str_]+ calc_data(chunk))\n",
    "    return results\n",
    "\n",
    "def calc_data(text): \n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if token.lemma_ != \"--\"]\n",
    "    count_part = Counter([lemma for lemma in lemmas if lemma in brut_final])\n",
    "    brut_sum = sum(count_part.values())\n",
    "    brut_types = len(count_part)\n",
    "    total_words = len(lemmas)\n",
    "    percentage = (brut_sum / total_words) * 100\n",
    "                       \n",
    "    return [brut_sum, brut_types, total_words, percentage]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dies hier wird weiter bearbeitet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set max_length according to your PC, the higher, the more RAM is required 100000 ~~ 1 GB\n",
    "nlp.max_length = 600000\n",
    "\n",
    "# Choose those you want to view/compare/plot later, results in DFs\n",
    "data_comp1 = get_brut_ratio(joined_text_krimi_W)\n",
    "data_comp1[\"field\"] = \"krimi_W\"\n",
    "data_comp2 = get_brut_ratio(joined_text_krimi_M)\n",
    "data_comp2[\"field\"] = \"krimi_M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_comp3 = get_brut_ratio(joined_text_aben_unsp)\n",
    "data_comp3[\"field\"] = \"aben_unsp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_final = pd.concat([data_comp1, data_comp2,\n",
    "                        #data_comp3\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_final.to_csv(\"csv_analyse_data_krimi.csv\", sep =\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_final = pd.read_csv(\"csv_analyse_data_hor.csv\", sep =\"|\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# to make sure to not lose data, plots can be saved, make sure you change filename if you use this option\n",
    "SAVE_FILES = True\n",
    "\n",
    "subdirectory = Path('plots')\n",
    "subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "#FILENAME- CHANGE THIS\n",
    "plot_name = 'bar_hor_full_brut_type.png'\n",
    "file_path = subdirectory / plot_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df =  data_final.sort_values('Percentage', ascending=True)#DataFrame mit den Anteilen der Adjektive hier einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Viewing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10, 20)})\n",
    "sns.barplot(x='Percentage', y='novel', hue='field', data=df)\n",
    "\n",
    "plt.xlabel('Percentage of Brutal words', fontsize = 25)\n",
    "plt.ylabel('Novel', fontsize = 25)\n",
    "\n",
    "highest_percentage = df['Percentage'].max()\n",
    "lowest_percentage = df['Percentage'].min()\n",
    "average_percentage = df['Percentage'].mean()\n",
    "\n",
    "text_highest = f'Highest: {highest_percentage:.2f}%'\n",
    "text_lowest = f'Lowest: {lowest_percentage:.2f}%'\n",
    "text_average = f'Average: {average_percentage:.2f}%'\n",
    "\n",
    "plt.annotate(text_highest, xy=(highest_percentage, len(df)-1), xytext=(10, 0),\n",
    "             ha='left', va='center', fontsize=20, xycoords='data', textcoords='offset points')\n",
    "plt.annotate(text_lowest, xy=(lowest_percentage, 0), xytext=(10, 0),\n",
    "             ha='left', va='center', fontsize=20, xycoords='data', textcoords='offset points')\n",
    "plt.annotate(text_average, xy=(average_percentage, len(df)//2), xytext=(10, 0),\n",
    "             ha='left', va='center', fontsize=20, xycoords='data', textcoords='offset points')\n",
    "\n",
    "if SAVE_FILES: plt.savefig(file_path, dpi= 300, bbox_inches ='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10, 10)})\n",
    "sns.barplot(data=df, x='field', y='Percentage', ci= None)\n",
    "\n",
    "# Calculate and display average and mean for each group\n",
    "average_per_group = df.groupby('field')['Percentage'].mean()\n",
    "mean_per_group = df.groupby('field')['Percentage'].median()\n",
    "total_words_sum = df['Total Words'].sum()\n",
    "\n",
    "for i, field in enumerate(df['field'].unique()):\n",
    "    plt.text(i, average_per_group[field], f'Avg: {average_per_group[field]:.2f}%', ha='center', va='bottom', fontsize=15)\n",
    "    plt.text(i, mean_per_group[field], f'Mean: {mean_per_group[field]:.2f}%', ha='center', va='top', fontsize=15)\n",
    "\n",
    "plt.xlabel('Field', fontsize=15)\n",
    "plt.ylabel('Percentage of Brutal words', fontsize=20)\n",
    "plt.title('Average and Mean by Field', fontsize=24)\n",
    "\n",
    "plt.text(0.5, 0.1, f\"Total Words Sum: {'{:,.0f}'.format(total_words_sum).replace(',', ' ')}\",\n",
    "         ha= \"center\", transform=plt.gca().transAxes, fontsize=25)\n",
    "    \n",
    "\n",
    "if SAVE_FILES: plt.savefig(file_path, dpi= 300, bbox_inches ='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Brut Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_avg_brut_type = df['brut_type'].mean()\n",
    "\n",
    "# Calculate the average of \"brut_type\" for each unique group in the 'field' column\n",
    "avg_brut_type_by_field = df.groupby('field')['brut_type'].mean()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a barplot to display the overall average and averages by field\n",
    "plt.bar(\"Overall\", overall_avg_brut_type, label='Overall Average', color='blue')\n",
    "for field, avg in avg_brut_type_by_field.items():\n",
    "    plt.bar(field, avg, label=f'Average in {field}', color='orange')\n",
    "\n",
    "plt.xlabel('Field', fontsize=15)\n",
    "plt.ylabel('Average of brut_type', fontsize=15)\n",
    "plt.title('Average of brut_type by Field', fontsize=18)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.legend(fontsize=12, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Specify the file path relative to the subdirectory and format (e.g., PNG)\n",
    "plt.savefig(file_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# To save in other formats, change the file extension (e.g., 'average_brut_type.jpg', 'average_brut_type.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df = data_final\n",
    "\n",
    "male_data = df[df['field'] == 'hor_M']['Percentage']\n",
    "female_data = df[df['field'] == 'hor_W']['Percentage']\n",
    "print(len(male_data))\n",
    "print(len(female_data))\n",
    "\n",
    "# Durchführung des T-Tests\n",
    "t_statistic, p_value = stats.ttest_ind(male_data, female_data, equal_var=True)\n",
    "\n",
    "# Ausgabe der Testergebnisse\n",
    "print(f'T-Statistik: {t_statistic}')\n",
    "print(f'p-Wert: {p_value}')\n",
    "\n",
    "# Interpretation der Ergebnisse\n",
    "alpha = 0.05  # Signifikanzniveau\n",
    "if p_value < alpha:\n",
    "    print(\"Der Unterschied im Anteil der brutalen Worte zwischen männlichen und weiblichen Autoren ist statistisch signifikant.\")\n",
    "else:\n",
    "    print(\"Es gibt keinen statistisch signifikanten Unterschied im Anteil der brutalen Worte zwischen männlichen und weiblichen Autoren.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
